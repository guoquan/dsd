{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of NvDocker interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "from dsd.sys.docker import NvDocker\n",
    "\n",
    "try:\n",
    "    socket.gethostbyname('dockerhost')\n",
    "    base_url = 'http://dockerhost:3476'\n",
    "except socket.error:\n",
    "    base_url = 'http://localhost:3476'\n",
    "    \n",
    "nvd = NvDocker(base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU global informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Version: 352.39\n",
      "CUDA Version: 7.5\n"
     ]
    }
   ],
   "source": [
    "globalInfo = nvd.gpuGlobalInfo()\n",
    "\n",
    "print 'Driver Version:', globalInfo['DriverVersion']\n",
    "print 'CUDA Version:', globalInfo['CudaVersion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Model: Tesla K40m\n",
      "Path: /dev/nvidia0\n",
      "Memory: 1446 / 11519 MB\n",
      "Utilization GPU: 80\n",
      "Utilization Memory: 36\n",
      "Temperature: 47\n",
      "         PID: 20401 | Name: /usr/bin/python | MemoryUsed: 73 MB\n",
      "         PID: 30093 | Name: python | MemoryUsed: 1347 MB\n",
      "####################\n",
      "Model: Tesla K40m\n",
      "Path: /dev/nvidia1\n",
      "Memory: 1510 / 11519 MB\n",
      "Utilization GPU: 81\n",
      "Utilization Memory: 37\n",
      "Temperature: 51\n",
      "         PID: 30093 | Name: python | MemoryUsed: 137 MB\n",
      "         PID: 31724 | Name: python | MemoryUsed: 1347 MB\n"
     ]
    }
   ],
   "source": [
    "gpuInfo = nvd.gpuInfo()\n",
    "\n",
    "for gpu in gpuInfo:\n",
    "    print '#' * 20\n",
    "    print 'Model:', gpu['Model']\n",
    "    print 'Path:', gpu['Path']\n",
    "    print 'Memory:', gpu['MemoryUsed'], '/', gpu['MemoryTotal'], 'MB'\n",
    "    \n",
    "    print 'Utilization GPU:', gpu['UtilizationGpu']\n",
    "    print 'Utilization Memory:', gpu['UtilizationMemory']\n",
    "    print 'Temperature:', gpu['Temperature']\n",
    "    \n",
    "    for p in gpu['Processes']:\n",
    "        print ' '*8, 'PID:', p['PID'], '| Name:', p['Name'], '| MemoryUsed:', p['MemoryUsed'], 'MB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Docker CLI parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VolumeDriver': '', 'Devices': [], 'Volumes': []}\n",
      "{'volumeDriver': '', 'devices': [], 'volumes': []}\n",
      "{u'VolumeDriver': u'nvidia-docker', u'Devices': [u'/dev/nvidia0', u'/dev/nvidia1', u'/dev/nvidiactl', u'/dev/nvidia-uvm'], u'Volumes': [u'nvidia_driver_352.39:/usr/local/nvidia:ro']}\n",
      "{'volumeDriver': u'nvidia-docker', 'devices': [HCP(h=u'/dev/nvidia0', c=None, p=None), HCP(h=u'/dev/nvidia1', c=None, p=None), HCP(h=u'/dev/nvidiactl', c=None, p=None), HCP(h=u'/dev/nvidia-uvm', c=None, p=None)], 'volumes': [HCP(h=u'nvidia_driver_352.39', c=u'/usr/local/nvidia', p=u'ro')]}\n",
      "{u'VolumeDriver': u'nvidia-docker', u'Devices': [u'/dev/nvidia1', u'/dev/nvidiactl', u'/dev/nvidia-uvm'], u'Volumes': [u'nvidia_driver_352.39:/usr/local/nvidia:ro']}\n",
      "{'volumeDriver': u'nvidia-docker', 'devices': [HCP(h=u'/dev/nvidia1', c=None, p=None), HCP(h=u'/dev/nvidiactl', c=None, p=None), HCP(h=u'/dev/nvidia-uvm', c=None, p=None)], 'volumes': [HCP(h=u'nvidia_driver_352.39', c=u'/usr/local/nvidia', p=u'ro')]}\n",
      "{u'VolumeDriver': u'nvidia-docker', u'Devices': [u'/dev/nvidia0', u'/dev/nvidia1', u'/dev/nvidiactl', u'/dev/nvidia-uvm'], u'Volumes': [u'nvidia_driver_352.39:/usr/local/nvidia:ro']}\n",
      "{'volumeDriver': u'nvidia-docker', 'devices': [HCP(h=u'/dev/nvidia0', c=None, p=None), HCP(h=u'/dev/nvidia1', c=None, p=None), HCP(h=u'/dev/nvidiactl', c=None, p=None), HCP(h=u'/dev/nvidia-uvm', c=None, p=None)], 'volumes': [HCP(h=u'nvidia_driver_352.39', c=u'/usr/local/nvidia', p=u'ro')]}\n"
     ]
    }
   ],
   "source": [
    "params = nvd.cliParams()\n",
    "print params\n",
    "params = nvd.cliParams([0, 1])\n",
    "print params\n",
    "params = nvd.cliParams([1])\n",
    "print params\n",
    "params = nvd.cliParams('all')\n",
    "print params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke a GPU enabled container\n",
    "## 1. get control objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dsd.sys.docker import PyDocker, HC, HCP\n",
    "from dsd.sys.docker import NvDocker\n",
    "\n",
    "import socket\n",
    "\n",
    "# get docker object\n",
    "try:\n",
    "    socket.gethostbyname('dockerhost')\n",
    "    base_url = 'http://dockerhost:4243'\n",
    "except socket.error:\n",
    "    base_url = 'unix:///var/run/docker.sock'\n",
    "    \n",
    "docker = PyDocker(base_url)\n",
    "\n",
    "try:\n",
    "    socket.gethostbyname('dockerhost')\n",
    "    base_url = 'http://dockerhost:3476'\n",
    "except socket.error:\n",
    "    base_url = 'http://localhost:3476'\n",
    "\n",
    "nvd = NvDocker(base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. build GPU image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# For Test\r\n",
      "FROM dsdgroup/jupyter:gpu\r\n",
      "MAINTAINER zy <zy3381@gmail.com>\r\n",
      "EXPOSE 9999\r\n",
      "\n",
      "{\"stream\":\"Step 1 : FROM dsdgroup/jupyter:gpu\\n\"}\r\n",
      "\n",
      "{\"stream\":\" ---\\u003e 1d0c98845267\\n\"}\r\n",
      "\n",
      "{\"stream\":\"Step 2 : MAINTAINER zy \\u003czy3381@gmail.com\\u003e\\n\"}\r\n",
      "\n",
      "{\"stream\":\" ---\\u003e Using cache\\n\"}\r\n",
      "\n",
      "{\"stream\":\" ---\\u003e 574da3156f96\\n\"}\r\n",
      "\n",
      "{\"stream\":\"Step 3 : EXPOSE 9999\\n\"}\r\n",
      "\n",
      "{\"stream\":\" ---\\u003e Using cache\\n\"}\r\n",
      "\n",
      "{\"stream\":\" ---\\u003e 4d3b7d2c17d2\\n\"}\r\n",
      "\n",
      "{\"stream\":\"Successfully built 4d3b7d2c17d2\\n\"}\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imageTag = 'buildtest:gpu'\n",
    "response = docker.build(tag=imageTag, dockerfilePath='../docker/test/gpu')\n",
    "if response:\n",
    "    for line in response:\n",
    "        print line\n",
    "else:\n",
    "    print 'build failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Run container by constructed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tty': True, 'name': 'container_test_gpu', 'image': 'buildtest:gpu', 'stdin_open': True, 'devices': [HCP(h=u'/dev/nvidia1', c=None, p=None), HCP(h=u'/dev/nvidiactl', c=None, p=None), HCP(h=u'/dev/nvidia-uvm', c=None, p=None)], 'volume_driver': u'nvidia-docker', 'command': None, 'user': None, 'volumes': [HCP(h=u'nvidia_driver_352.39', c=u'/usr/local/nvidia', p=u'ro')], 'detach': True, 'ports': [HC(h=1234, c=8888), HC(h=5678, c=7777), HC(h=None, c=9999)]}\n",
      "buildtest:gpu True True True None container_test_gpu None [HC(h=1234, c=8888), HC(h=5678, c=7777), HC(h=None, c=9999)] [HCP(h=u'/dev/nvidia1', c=None, p=None), HCP(h=u'/dev/nvidiactl', c=None, p=None), HCP(h=u'/dev/nvidia-uvm', c=None, p=None)] [HCP(h=u'nvidia_driver_352.39', c=u'/usr/local/nvidia', p=u'ro')] None\n",
      "Container 37fc020dc777c239ffe24e263465c77b5cea96e8e0e5751f019d72851edf0d10 created!\n",
      "start:  True\n"
     ]
    }
   ],
   "source": [
    "params = nvd.cliParams(dev=[1])\n",
    "params['image'] = 'buildtest:gpu'\n",
    "params['detach'] = True\n",
    "params['stdin_open'] = True\n",
    "params['tty'] = True\n",
    "params['command'] = None #'nvidia-smi'\n",
    "params['name'] = 'container_test_gpu'\n",
    "params['user'] = None\n",
    "params['ports'] = [HC(1234, 8888), HC(5678, 7777), HC(c=9999)]\n",
    "\n",
    "\n",
    "print params\n",
    "\n",
    "#container = docker.create(**params) # WHAT'S WRONG IN THIS LINE?\n",
    "container = docker.create(image=params['image'], \n",
    "           detach=params['detach'], \n",
    "           stdin_open=params['stdin_open'], \n",
    "           tty=params['tty'], \n",
    "           command=params['command'], \n",
    "           name=params['name'],\n",
    "           user=params['user'],\n",
    "           ports=params['ports'],\n",
    "           volumes=params['volumes'],\n",
    "           devices=params['devices']\n",
    "           )\n",
    "\n",
    "if container:\n",
    "    print 'Container %s created!' % container.get('Id')\n",
    "    \n",
    "response = docker.start(container=container.get('Id'))\n",
    "print 'start: ', response\n",
    "\n",
    "# IT SEEMS devices are OK,\n",
    "# BUT volumes are not corrected mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop:  True\n",
      "rm:  True\n"
     ]
    }
   ],
   "source": [
    "response = docker.stop(container=container.get('Id'), timeout=0)\n",
    "print 'stop: ', response\n",
    "\n",
    "response = docker.rm(container=container.get('Id'), )\n",
    "print 'rm: ', response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
